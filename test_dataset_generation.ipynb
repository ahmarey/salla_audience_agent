{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36fe9064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully generated 40 test cases and saved to tests/test_data_2.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_relative_date(days: int, past: bool = True) -> str:\n",
    "    \"\"\"Calculates a date in YYYY-MM-DD format relative to today.\"\"\"\n",
    "    if past:\n",
    "        target_date = datetime.now() - timedelta(days=days)\n",
    "    else:\n",
    "        target_date = datetime.now() + timedelta(days=days)\n",
    "    return target_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def generate_test_cases():\n",
    "    \"\"\"\n",
    "    Generates a list of test cases from a set of templates.\n",
    "    \"\"\"\n",
    "    test_cases = []\n",
    "\n",
    "    # --- Define Templates ---\n",
    "    # Each template defines a type of filter and provides variations.\n",
    "    templates = [\n",
    "        # --- EQUALITY / NEGATION ---\n",
    "        {\n",
    "            \"field\": \"gender\", \"operator\": \"=\", \"type\": str,\n",
    "            \"prompts_en\": [\"Find {value} customers\", \"Show me the {value} clients\", \"{value} users\"],\n",
    "            \"prompts_ar\": [\"اعثر على العملاء من {value}\", \"أرني العملاء الـ {value}\", \"المستخدمون الـ {value}\"],\n",
    "            \"values\": [{\"en\": \"male\", \"ar\": \"ذكور\"}, {\"en\": \"female\", \"ar\": \"إناث\"}]\n",
    "        },\n",
    "        {\n",
    "            \"field\": \"country\", \"operator\": \"!=\", \"type\": str,\n",
    "            \"prompts_en\": [\"Everyone except those from {value}\", \"All users not in {value}\"],\n",
    "            \"prompts_ar\": [\"الجميع ما عدا أولئك من {value}\", \"كل المستخدمين ليسوا في {value}\"],\n",
    "            \"values\": [{\"en\": \"Egypt\", \"ar\": \"مصر\"}, {\"en\": \"KSA\", \"ar\": \"السعودية\"}]\n",
    "        },\n",
    "        # --- NUMERIC COMPARISONS ---\n",
    "        {\n",
    "            \"field\": \"total_orders\", \"operator\": \">\", \"type\": int,\n",
    "            \"prompts_en\": [\"Customers with more than {value} orders\", \"Users who ordered over {value} times\"],\n",
    "            \"prompts_ar\": [\"العملاء الذين لديهم أكثر من {value} طلبات\", \"المستخدمون الذين طلبوا أكثر من {value} مرات\"],\n",
    "            \"values\": [5, 50, 100]\n",
    "        },\n",
    "        {\n",
    "            \"field\": \"total_sales\", \"operator\": \"<=\", \"type\": float,\n",
    "            \"prompts_en\": [\"Clients with total sales of {value} or less\", \"Sales at most {value}\"],\n",
    "            \"prompts_ar\": [\"العملاء الذين تبلغ مبيعاتهم الإجمالية {value} أو أقل\", \"المبيعات بحد أقصى {value}\"],\n",
    "            \"values\": [100.50, 5000.0, 999.99]\n",
    "        },\n",
    "        # --- DATE COMPARISONS ---\n",
    "        {\n",
    "            \"field\": \"joining_date\", \"operator\": \">=\", \"type\": \"date\",\n",
    "            \"prompts_en\": [\"Customers who joined in the last {value} days\", \"Signups from the past {value} days\"],\n",
    "            \"prompts_ar\": [\"العملاء الذين انضموا في آخر {value} يومًا\", \"التسجيلات من آخر {value} يوم\"],\n",
    "            \"values\": [7, 30, 90]\n",
    "        },\n",
    "        # --- BETWEEN OPERATOR ---\n",
    "        {\n",
    "            \"field\": \"store_rating\", \"operator\": \"between\", \"type\": float,\n",
    "            \"prompts_en\": [\"Stores rated between {v1} and {v2} stars\", \"Find ratings from {v1} to {v2}\"],\n",
    "            \"prompts_ar\": [\"المتاجر التي تقييمها بين {v1} و {v2} نجوم\", \"اعثر على التقييمات من {v1} إلى {v2}\"],\n",
    "            \"values\": [[3.0, 5.0], [1.5, 3.5]]\n",
    "        },\n",
    "        # --- BOOLEAN FLAGS ---\n",
    "        {\n",
    "            \"field\": \"have_cancelled_orders\", \"operator\": \"=\", \"type\": bool,\n",
    "            \"prompts_en\": [\"Users who have cancelled orders\", \"Find people with cancelled orders\"],\n",
    "            \"prompts_ar\": [\"المستخدمون الذين لديهم طلبات ملغاة\", \"اعثر على الأشخاص أصحاب الطلبات الملغاة\"],\n",
    "            \"values\": [True]\n",
    "        },\n",
    "        # --- LISTS (OR logic) ---\n",
    "        {\n",
    "            \"field\": \"city\", \"operator\": \"=\", \"type\": list,\n",
    "            \"prompts_en\": [\"Users in {v1} or {v2}\", \"Customers from {v1}, {v2}\"],\n",
    "            \"prompts_ar\": [\"المستخدمون في {v1} أو {v2}\", \"عملاء من {v1}، {v2}\"],\n",
    "            \"values\": [[\"Riyadh\", \"Jeddah\"], [\"Cairo\", \"Alexandria\"]]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # --- Generate Test Cases ---\n",
    "    for template in templates:\n",
    "        for value in template[\"values\"]:\n",
    "            for i, prompt_en_template in enumerate(template[\"prompts_en\"]):\n",
    "                prompt_ar_template = template[\"prompts_ar\"][i]\n",
    "\n",
    "                # Handle different value structures\n",
    "                if template[\"operator\"] == \"between\":\n",
    "                    v1, v2 = value\n",
    "                    prompt_en = prompt_en_template.format(v1=v1, v2=v2)\n",
    "                    prompt_ar = prompt_ar_template.format(v1=v1, v2=v2)\n",
    "                    expected_value = [template[\"type\"](v) for v in value]\n",
    "                elif template[\"type\"] == list:\n",
    "                    v1, v2 = value\n",
    "                    prompt_en = prompt_en_template.format(v1=v1, v2=v2)\n",
    "                    prompt_ar = prompt_ar_template.format(v1=v1, v2=v2)\n",
    "                    expected_value = value\n",
    "                elif template[\"type\"] == str:\n",
    "                    prompt_en = prompt_en_template.format(value=value[\"en\"])\n",
    "                    prompt_ar = prompt_ar_template.format(value=value[\"ar\"])\n",
    "                    expected_value = value[\"en\"]\n",
    "                elif template[\"type\"] == \"date\":\n",
    "                    prompt_en = prompt_en_template.format(value=value)\n",
    "                    prompt_ar = prompt_ar_template.format(value=value)\n",
    "                    expected_value = get_relative_date(value)\n",
    "                else:\n",
    "                    prompt_en = prompt_en_template.format(value=value)\n",
    "                    prompt_ar = prompt_ar_template.format(value=value)\n",
    "                    expected_value = template[\"type\"](value)\n",
    "\n",
    "                case_id = f\"{template['field']}_{template['operator']}_{i}_{str(value).replace(' ', '')}\"\n",
    "                \n",
    "                test_case = {\n",
    "                    \"id\": case_id,\n",
    "                    \"prompt_en\": prompt_en,\n",
    "                    \"prompt_ar\": prompt_ar,\n",
    "                    \"expected_status\": 200,\n",
    "                    \"expected_output\": {\n",
    "                        \"filters\": [{\n",
    "                            \"field\": template[\"field\"],\n",
    "                            \"operator\": template[\"operator\"],\n",
    "                            \"value\": expected_value\n",
    "                        }]\n",
    "                    }\n",
    "                }\n",
    "                test_cases.append(test_case)\n",
    "\n",
    "    # --- Manually add complex/error cases ---\n",
    "    test_cases.append({\n",
    "        \"id\": \"multi_filter_complex_ar\",\n",
    "        \"prompt_en\": \"Female users from Egypt with sales over 1000\",\n",
    "        \"prompt_ar\": \"المستخدمات الإناث من مصر بمبيعات تزيد عن 1000\",\n",
    "        \"expected_status\": 200,\n",
    "        \"expected_output\": {\n",
    "            \"filters\": [\n",
    "                {\"field\": \"gender\", \"operator\": \"=\", \"value\": \"female\"},\n",
    "                {\"field\": \"country\", \"operator\": \"=\", \"value\": \"Egypt\"},\n",
    "                {\"field\": \"total_sales\", \"operator\": \">\", \"value\": 1000.0}\n",
    "            ]\n",
    "        }\n",
    "    })\n",
    "    test_cases.append({\n",
    "        \"id\": \"error_unsupported_field\",\n",
    "        \"prompt_en\": \"Customers with a high net promoter score\",\n",
    "        \"prompt_ar\": \"العملاء الذين لديهم درجة رضا عالية\",\n",
    "        \"expected_status\": 400,\n",
    "        \"expected_output\": {\"detail\": \"No valid filters were found. The prompt may contain unsupported fields or be too ambiguous.\"}\n",
    "    })\n",
    "\n",
    "    return test_cases\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate the test data\n",
    "    all_test_cases = generate_test_cases()\n",
    "    \n",
    "    # Write to a JSON file\n",
    "    with open(\"tests/test_data_2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_test_cases, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"✅ Successfully generated {len(all_test_cases)} test cases and saved to tests/test_data_2.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "def run_single_test(case, language):\n",
    "    \"\"\"\n",
    "    Runs a single test case against the API.\n",
    "\n",
    "    Args:\n",
    "        case (dict): A dictionary representing a single test case.\n",
    "        language (str): 'en' for English prompt, 'ar' for Arabic.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the test passed, False otherwise.\n",
    "    \"\"\"\n",
    "    prompt_key = f\"prompt_{language}\"\n",
    "    prompt_text = case[prompt_key]\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\", # Be explicit about charset\n",
    "        # \"x-api-key\": API_KEY\n",
    "    }\n",
    "    if API_KEY:\n",
    "        headers[\"x-api-key\"] = API_KEY\n",
    "    payload = {\"prompt\": prompt_text}\n",
    "\n",
    "    # Manually serialize the dictionary to a JSON string and encode it to UTF-8\n",
    "    data_to_send = json.dumps(payload, ensure_ascii=False).encode('utf-8')\n",
    "\n",
    "    try:\n",
    "        # Use the `data` parameter instead of `json` since we manually encoded it\n",
    "        response = requests.post(API_URL, headers=headers, data=data_to_send, timeout=30)\n",
    "        \n",
    "        # 1. Check if the status code matches\n",
    "        if response.status_code != case[\"expected_status\"]:\n",
    "            print(f\"\\n❌ FAILED: {case['id']} ({language.upper()})\")\n",
    "            print(f\"  Reason: Status Code Mismatch\")\n",
    "            print(\"data_to_send:\", data_to_send)\n",
    "            print(f\"  Expected: {case['expected_status']}\")\n",
    "            print(f\"  Got: {response.status_code}\")\n",
    "            print(f\"  Response: {response.text}\")\n",
    "            return False\n",
    "            \n",
    "        # 2. Check if the JSON body matches\n",
    "        response_json = response.json()\n",
    "        if response_json != case[\"expected_output\"]:\n",
    "            print(f\"\\n❌ FAILED: {case['id']} ({language.upper()})\")\n",
    "            print(\"data_to_send:\", data_to_send)\n",
    "            print(f\"  Reason: JSON Output Mismatch\")\n",
    "            # Use json.dumps with ensure_ascii=False to handle Unicode characters\n",
    "            print(f\"  Expected: {json.dumps(case['expected_output'], ensure_ascii=False)}\")\n",
    "            print(f\"  Got: {json.dumps(response_json, ensure_ascii=False)}\")\n",
    "            return False\n",
    "\n",
    "        # If both checks pass\n",
    "        return True\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\n❌ FAILED: {case['id']} ({language.upper()})\")\n",
    "        print(f\"  Reason: API Request Failed\")\n",
    "        print(f\"  Error: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e8be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not API_URL or not API_KEY:\n",
    "    print(\"🚨 ERROR: Please set the API_URL and API_KEY environment variables.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95eec632",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(TEST_DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        test_cases = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"🚨 ERROR: Test data file not found at {TEST_DATA_PATH}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ead355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting API accuracy test with 42 total prompts...\n"
     ]
    }
   ],
   "source": [
    "passed_tests = 0\n",
    "# Each case has an English and an Arabic prompt, so we double the count\n",
    "total_tests = len(test_cases) * 2\n",
    "\n",
    "print(f\"🚀 Starting API accuracy test with {total_tests} total prompts...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deployment\n",
    "API_URL = \"https://w2xhkmywby.us-east-2.awsapprunner.com/parse_prompt\" #os.getenv(\"API_URL\")\n",
    "API_KEY = \"blabla\" #os.getenv(\"API_KEY\")\n",
    "#local\n",
    "# API_URL = \"http://127.0.0.1:8000/parse_prompt\" #os.getenv(\"API_URL\")\n",
    "# API_KEY = \"\" #os.getenv(\"API_KEY\")\n",
    "\n",
    "TEST_DATA_PATH = \"tests/test_data_2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba8e93c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [00:48<00:01,  1.34s/prompt]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ FAILED: error_unsupported_field (EN)\n",
      "data_to_send: b'{\"prompt\": \"Customers with a high net promoter score\"}'\n",
      "  Reason: JSON Output Mismatch\n",
      "  Expected: {\"filters\": [{\"field\": \"store_rating\", \"operator\": \">\", \"value\": 4.0}]}\n",
      "  Got: {\"detail\": \"No valid filters were found. The prompt may contain unsupported fields or be too ambiguous.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:49<00:00,  1.19s/prompt]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ FAILED: error_unsupported_field (AR)\n",
      "  Reason: Status Code Mismatch\n",
      "data_to_send: b'{\"prompt\": \"\\xd8\\xa7\\xd9\\x84\\xd8\\xb9\\xd9\\x85\\xd9\\x84\\xd8\\xa7\\xd8\\xa1 \\xd8\\xa7\\xd9\\x84\\xd8\\xb0\\xd9\\x8a\\xd9\\x86 \\xd9\\x84\\xd8\\xaf\\xd9\\x8a\\xd9\\x87\\xd9\\x85 \\xd8\\xaf\\xd8\\xb1\\xd8\\xac\\xd8\\xa9 \\xd8\\xb1\\xd8\\xb6\\xd8\\xa7 \\xd8\\xb9\\xd8\\xa7\\xd9\\x84\\xd9\\x8a\\xd8\\xa9\"}'\n",
      "  Expected: 400\n",
      "  Got: 200\n",
      "  Response: {\"filters\":[{\"field\":\"store_rating\",\"operator\":\">\",\"value\":4.0}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm for a progress bar\n",
    "#deployment\n",
    "passed_tests = 0\n",
    "\n",
    "with tqdm(total=total_tests, unit=\"prompt\") as pbar:\n",
    "    for case in test_cases:\n",
    "        # Test English prompt\n",
    "        if run_single_test(case, \"en\"):\n",
    "            passed_tests += 1\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Test Arabic prompt\n",
    "        if run_single_test(case, \"ar\"):\n",
    "            passed_tests += 1\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa37a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "📊 FINAL ACCURACY REPORT\n",
      "  Tests Passed: 40\n",
      "  Total Prompts: 42\n",
      "  Accuracy: 95.24%\n",
      "✅ Success! Accuracy meets the >= 90% requirement.\n"
     ]
    }
   ],
   "source": [
    "## deployment\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📊 FINAL ACCURACY REPORT\")\n",
    "\n",
    "accuracy = (passed_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "print(f\"  Tests Passed: {passed_tests}\")\n",
    "print(f\"  Total Prompts: {total_tests}\")\n",
    "print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "if accuracy >= 90:\n",
    "    print(\"✅ Success! Accuracy meets the >= 90% requirement.\")\n",
    "else:\n",
    "    print(\"⚠️ Warning! Accuracy is below the 90% requirement.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03d0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [00:45<00:01,  1.15s/prompt]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ FAILED: error_unsupported_field (EN)\n",
      "data_to_send: b'{\"prompt\": \"Customers with a high net promoter score\"}'\n",
      "  Reason: JSON Output Mismatch\n",
      "  Expected: {\"filters\": [{\"field\": \"store_rating\", \"operator\": \">\", \"value\": 4.0}]}\n",
      "  Got: {\"detail\": \"No valid filters were found. The prompt may contain unsupported fields or be too ambiguous.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:46<00:00,  1.10s/prompt]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ FAILED: error_unsupported_field (AR)\n",
      "  Reason: Status Code Mismatch\n",
      "data_to_send: b'{\"prompt\": \"\\xd8\\xa7\\xd9\\x84\\xd8\\xb9\\xd9\\x85\\xd9\\x84\\xd8\\xa7\\xd8\\xa1 \\xd8\\xa7\\xd9\\x84\\xd8\\xb0\\xd9\\x8a\\xd9\\x86 \\xd9\\x84\\xd8\\xaf\\xd9\\x8a\\xd9\\x87\\xd9\\x85 \\xd8\\xaf\\xd8\\xb1\\xd8\\xac\\xd8\\xa9 \\xd8\\xb1\\xd8\\xb6\\xd8\\xa7 \\xd8\\xb9\\xd8\\xa7\\xd9\\x84\\xd9\\x8a\\xd8\\xa9\"}'\n",
      "  Expected: 400\n",
      "  Got: 200\n",
      "  Response: {\"filters\":[{\"field\":\"store_rating\",\"operator\":\">\",\"value\":4.0}]}\n",
      "\n",
      "==================================================\n",
      "📊 FINAL ACCURACY REPORT\n",
      "  Tests Passed: 40\n",
      "  Total Prompts: 42\n",
      "  Accuracy: 95.24%\n",
      "✅ Success! Accuracy meets the >= 90% requirement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm for a progress bar\n",
    "#local\n",
    "passed_tests = 0\n",
    "with tqdm(total=total_tests, unit=\"prompt\") as pbar:\n",
    "    for case in test_cases:\n",
    "        # Test English prompt\n",
    "        if run_single_test(case, \"en\"):\n",
    "            passed_tests += 1\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Test Arabic prompt\n",
    "        if run_single_test(case, \"ar\"):\n",
    "            passed_tests += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📊 FINAL ACCURACY REPORT\")\n",
    "\n",
    "accuracy = (passed_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "print(f\"  Tests Passed: {passed_tests}\")\n",
    "print(f\"  Total Prompts: {total_tests}\")\n",
    "print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "if accuracy >= 90:\n",
    "    print(\"✅ Success! Accuracy meets the >= 90% requirement.\")\n",
    "else:\n",
    "    print(\"⚠️ Warning! Accuracy is below the 90% requirement.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e77f44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [00:44<00:01,  1.14s/prompt]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ FAILED: error_unsupported_field (EN)\n",
      "data_to_send: b'{\"prompt\": \"Customers with a high net promoter score\"}'\n",
      "  Reason: JSON Output Mismatch\n",
      "  Expected: {\"filters\": [{\"field\": \"store_rating\", \"operator\": \">\", \"value\": 4.0}]}\n",
      "  Got: {\"detail\": \"No valid filters were found. The prompt may contain unsupported fields or be too ambiguous.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:45<00:00,  1.09s/prompt]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ FAILED: error_unsupported_field (AR)\n",
      "  Reason: Status Code Mismatch\n",
      "data_to_send: b'{\"prompt\": \"\\xd8\\xa7\\xd9\\x84\\xd8\\xb9\\xd9\\x85\\xd9\\x84\\xd8\\xa7\\xd8\\xa1 \\xd8\\xa7\\xd9\\x84\\xd8\\xb0\\xd9\\x8a\\xd9\\x86 \\xd9\\x84\\xd8\\xaf\\xd9\\x8a\\xd9\\x87\\xd9\\x85 \\xd8\\xaf\\xd8\\xb1\\xd8\\xac\\xd8\\xa9 \\xd8\\xb1\\xd8\\xb6\\xd8\\xa7 \\xd8\\xb9\\xd8\\xa7\\xd9\\x84\\xd9\\x8a\\xd8\\xa9\"}'\n",
      "  Expected: 400\n",
      "  Got: 200\n",
      "  Response: {\"filters\":[{\"field\":\"store_rating\",\"operator\":\">\",\"value\":4.0}]}\n",
      "\n",
      "==================================================\n",
      "📊 FINAL ACCURACY REPORT\n",
      "  Tests Passed: 40\n",
      "  Total Prompts: 42\n",
      "  Accuracy: 95.24%\n",
      "✅ Success! Accuracy meets the >= 90% requirement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm for a progress bar\n",
    "#local\n",
    "passed_tests = 0\n",
    "\n",
    "with tqdm(total=total_tests, unit=\"prompt\") as pbar:\n",
    "    for case in test_cases:\n",
    "        # Test English prompt\n",
    "        if run_single_test(case, \"en\"):\n",
    "            passed_tests += 1\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Test Arabic prompt\n",
    "        if run_single_test(case, \"ar\"):\n",
    "            passed_tests += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📊 FINAL ACCURACY REPORT\")\n",
    "\n",
    "accuracy = (passed_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "print(f\"  Tests Passed: {passed_tests}\")\n",
    "print(f\"  Total Prompts: {total_tests}\")\n",
    "print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "if accuracy >= 90:\n",
    "    print(\"✅ Success! Accuracy meets the >= 90% requirement.\")\n",
    "else:\n",
    "    print(\"⚠️ Warning! Accuracy is below the 90% requirement.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
